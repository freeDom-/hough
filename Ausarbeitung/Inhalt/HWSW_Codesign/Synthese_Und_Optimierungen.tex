Für die Auslagerung der Module auf den \ac{FPGA} müssen diese zunächst in Hardware umgewandelt werden. Die im vorigen Kapitel vorgestellten Softwareimplementierungen werden dazu mittels Vivado HLS zu einem \ac{RTL} synthetisiert. Anschließend wird das \ac{RTL} über eine C/\ac{RTL} Cosimulation verifiziert und kann schließlich als \ac{IP} in Vivado 2017.4 zum Hardware/Software Codesign verwendet werden. Die Entwicklungsumgebung liefert bei der Synthese bereits approximierte Daten bezüglich der Laufzeit und der benötigten Ressourcen. Die erzeugten Daten bieten einen ersten Anhaltspunkt für die weitere Optimierung.
\\
\\
Vor der eigentlichen Synthese muss überprüft werden, ob die gegebene Funktion überhaupt synthetisiert werden kann. Die Softwareimplementierung ist grundsätzlich nur dann synthetisierbar, wenn keine dynamischen Speicherallokationen vorliegen und alle C-Konstrukte eine feste oder beschränkte Größe besitzen. Weiterhin dürfen keine rekursiven Funktionen verwendet werden und die Ein- und Ausgabedaten der Funktion müssen als Parameter implementiert werden. Wenn eines der Kriterien nicht erfüllt ist, müssen zunächst entsprechende Veränderungen am Code vorgenommen werden.
\cite[S. 313ff]{vivado902ug}
\\
\\
Jedes Hardwaremodul benötigt Schnittstellen für den Datenaustausch. Im ersten Schritt der Synthese müssen die Schnittstellen definiert werden. Vivado HLS definiert standardmäßig alle Argumente einer Funktion als Schnittstellen, über die Daten empfangen oder gesendet werden können. Außerdem können im Programm Schnittstellen über Direktiven für die jeweiligen Argumente manuell definiert werden. Für die Kommunikation mit dem \ac{PS} wird das \ac{AXI4} verwendet \cite[S. 167ff]{vivado902ug}. Mit diesem können mehrere Schnittstellen zu einem Bus zusammengefasst werden. Bei der Synthese eines Moduls, welches das \ac{AXI4} verwendet, werden automatisch C-Treiber generiert. Diese stellen ein \ac{API} zur Ansteuerung des synthetisierten Moduls bereit. Die Argumente, welche eine sequentielle Verarbeitung der Daten zulassen, sollten zudem als HLS Stream \cite[S. 263-270]{vivado902ug} implementiert werden. Die \ac{HLS} kann damit besser umgehen und deshalb resultieren daraus Designs, die eine bessere Performance haben und weniger Ressourcen benötigen. \cite[S. 113ff]{vivado902ug}
\\
\\
Die Optimierung findet in zwei Schritten statt: Zuerst wird die Laufzeit minimiert. Dafür ist vor allem das Pipelining von Schleifen und Funktionen sowie das Loop unrolling verantwortlich. In den folgenden Abschnitten werden diese Techniken näher erläutert.
\\
\\
Loop unrolling bezeichnet das Zusammenfassen von mehreren Iterationsschritten einer Schleife. Dabei kann eine Schleife teilweise oder vollständig unrolled werden. Beim vollständigen Unrollen werden alle Iterationsschritte, sofern möglich, parallel ausgeführt. In \autoref{img:loop_unrolling} sind die verschiedenen Varianten des Loop unrollings aufgeführt. In der gezeigten Schleife müssen in einem Takt zwei Daten gelesen, eine Operation ausgeführt und ein Wert geschrieben werden. Die komplette Abarbeitung der Schleife dauert dann vier Takte. Wenn die Schleife vollständig unrolled wird, dauert die Abarbeitung nur einen Takt, dafür müssen allerdings acht Werte gelesen, vier Operationen ausgeführt und vier Werte geschrieben werden. Die Felder a, b, und c aus dem Beispiel werden im \ac{BRAM} gespeichert. Da dieser nur maximal zwei Zugriffe pro Takt erlaubt, müssen die Felder zusätzlich partitioniert werden, um die gesamte Schleife in einem Takt abzuarbeiten. Loop unrolling ist nur möglich, wenn die Schleife feste Iterationsgrenzen besitzt. Der Kompromiss zwischen Laufzeitersparnis und erhöhtem Hardwareaufwand muss in jedem Fall im Einzelnen betrachtet werden.
\cite[S. 199-202]{vivado902ug}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{Bilder/loop_unrolling.pdf}
	\caption{Loop unrolling}
	\label{img:loop_unrolling}
\end{figure}

Das Partitionieren von Feldern bezeichnet die Unterteilung von einem Feld auf mehrere Speichereinheiten, damit die Anzahl der möglichen Zugriffe pro Takt erhöht wird. Felder können komplett, zyklisch oder blockweise partitioniert werden. Bei der kompletten Partitionierung wird das gesamte Feld zerlegt und jedes Element in einem eigenen Register gespeichert. Bei einer blockweisen Partitionierung werden $n$ gleichgroße Blöcke gebildet, welche die einzelnen Elemente fortlaufend enthalten. Bei der zyklischen Partitionierung werden ebenfalls $n$ gleichgroße Blöcke gebildet. Diese enthalten die Daten allerdings zyklisch. Wenn jeder Block $N$ Elemente enthält, dann enthält der $i$-te Block die folgende Menge an Elementen: $\sum_{i=0}^{n} elem_i = \{i, n+i, 2*n+i, ..., N*n+i\}$.
\cite[S. 194-196]{vivado902ug}
\\
Die zyklische Partitionierung ist sinnvoll, um gleichzeitig auf mehrere hintereinander liegende Elemente zuzugreifen. Die blockweise Partitionierung ist dagegen einzusetzen, wenn die Daten, auf die gleichzeitig zugegriffen wird, weiter auseinander liegen.
\\
\\
Das Pipelining von Schleifen wurde bereits in \autoref{sec:pipelining} beschrieben. Bei verschachtelten Schleifen sollte zur Optimierung der Laufzeit immer mit dem Pipelining der innersten Schleife begonnen werden, da das Pipelining der äußeren Schleifen nicht immer möglich ist. Wenn dies erfolgreich ist können schrittweise die äußeren Schleifen statt den inneren gepipelined werden. So wird eine gute Übersicht über den Laufzeitgewinn und den unterschiedlichen Ressourcenverbauch erzielt.
\\
Pipelining ist jedoch nicht immer möglich. Beim Pipelining verschachtelter Schleifen darf nur die innerste Schleife Anweisungen enthalten. Außerdem ist das Pipelining einer äußeren Schleife, die eine oder mehrere innere Schleifen enthält, nur nach vorherigem Unrollen aller inneren Schleifen möglich. Wenn diese nicht unrolled werden können, kann auch die äußere Schleife nicht gepipelined werden.
\cite[S. 188-209]{vivado902ug}
\\
\\
Wenn die Laufzeit zufriedenstellend optimiert wurde und Verbesserungen nur noch mit erheblichem Ressourcenaufwand erzielt werden können, kann das Design hinsichtlich des Ressourcenverbrauchs optimiert werden. Hierbei können vor allem durch Datenflussdirektiven oder durch Zusammenfassen mehrerer kleiner Felder zu einem großen Feld im \ac{BRAM} (Array Mapping) Verbesserungen erzielt werden.
\cite[S. 210-219]{vivado902ug}
\\
\\
\autoref{img:arm_laufzeit400x400} zeigt einen Aufruf der seriellen, und der parallelen Version des Programmes. Daraus geht hervor, dass durch die Parallelisierung bereits eine ungefähr 2,5-fache Laufzeitbeschleunigung erzielt werden kann. Darüber hinaus kann der Grafik entnommen werden, dass das Modul für die \ac{CHT} eindeutig am meisten Zeit benötigt. Das Modul für die Canny Edge Detection ist nach der \ac{CHT} das langsamste Modul, aber mit einer Laufzeit von 81ms immer noch ungefähr 13-mal schneller als die \ac{CHT}. Daher soll der Fokus für die Optimierung und Auslagerung in die Hardware auf das \ac{CHT} Modul gelegt werden. In den folgenden Kapiteln wird die \ac{HLS} deshalb zunächst als einleitendes Beispiel für das Grayscaler Modul und anschließend für das \ac{CHT} Modul durchgeführt.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{Bilder/arm_laufzeit400x400.png}
	\caption[Laufzeit der Softwareimplementierung der Hough Transformation]{Laufzeit der Softwareimplementierung der \ac{HT} für ein 400x400 Pixel großes Bild auf dem Cortex-A53}
	\label{img:arm_laufzeit400x400}
\end{figure}
